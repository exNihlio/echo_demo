## What is this?

A simple API server written in Python with Bottle.
It takes a JSON encoded body and echoes it back with the added
key/value of `"echoed": true"`. Additionally, if you return that
same body and it detects the `"echoed": true"` key/value, it returns
an error.
### Contents
1. [Usage](#Usage)
2. [Architecture](#Architecture)
3. [Testing](#Testing)
4. [Performance](#Performance)
5. [Service Objectives](#SLA)

## Usage

### Build the Docker image
`docker build -t echo:1 .`

### Run the Docker container
`docker run --rm -d -p 8080:8080 echo:1`

### Validate that the server is running correctly

`curl -v --header "Content-Type: application/json" --data '{"foo": "bar"}' -XPOST  http://127.0.0.1:8080/api/echo`

If everything is working correctly you should see the following:

`{"foo": "bar", "echoed": true}`

## Architecture
The web framework is written in Python and leverages `bottle` to act as the web framework.
Bottle was chosen because it is fairly simple and reasonably performant. It is served
with Gunicorn, again chosen for simplicity and reasonable speed/resource requirements.
Gunicorn can scale fairly well (for a Python application).

As above, Python was chose for it's middle of the road functionality and acceptable
performance and it is well know by the author. Perl could probably have been much faster,
but introduces complexity and maintainability issues. For this kind of project Golang makes
a better choice, being more secure with fewer dependencies and having actual concurrency,
but the author is less familiar with Golang.

As required, the application simply accepts a JSON formatted body from a client and
echoes it back with the appended key/value of `{"echoed": true}`, provided the following
conditions are met:

1. The client used either a POST/PUT HTTP method
2. The header includes a `Content-Type: application/json`
3. The data is sent to the `/api/echo` path.
4. The data does NOT already include a `{"echoed": true}` key


The application code contains only two routes, a `/` and `/api/echo`. The `/` route
is only used for testing/landing and responds with an ASCII cow. The function of the
`/api/echo` route has already been discussed.

## Testing

A series of simple validation tests can be accomplished with running:

`python3 tests.py`

These validate the API is functioning correctly and returning the correct HTTP codes.
It accomplishes the following:

1. It simply verifies that it can connect to a running server, reading in the same
environmental variables used to configure gunicorn. If it cannot connect, no
further testing is accomplished. To test connectivity it performs an HTTP GET to
`/` path. `httpx` is used for client requests.

2. The second test is to post to the `/api/echo` path using a `text/html` content
header, validating that server does respond with an HTTP 415

3. It then checks that POST and PUT methods are accepted to the `/api/echo` path

4. It then validates that data is echoed back correctly with a small test document:
```
{
  "kitten_status": "adorable",
  "puppy_status": "precious"
}
```
5. Next the script sends that same document and then re-sends the echoed data, first
validating that it receives an HTTP 400, then also verifying that server does not echo back
the previously echoed data.

## Performance

As stated before, Python, Bottle and Gunicorn are reasonably performant. Simple load testing
was performed using `hey` a Golang based load tester. The author tested this on a Macbook Air
running Docker. The Macbook has the following specs:

1.6Ghz dual-core Intel i5

8GB of LPDDR3 RAM @2133Mhz

The Docker container was configured as follows:

`docker run -it --rm -d --cpus 1 --memory 1024m -p 8080:8080 echo:1`

This provided the container with a single CPU and 1GB of memory.

`hey` was then configured to run as follows:

`hey -c 100 -n 10000 -m PUT -H "Content-Type: application/json" -D ~/data.json http://localhost:8080/api/echo`

The `~/data.json` is a JSON document of approximately 1.3K, randomly generated by https://www.json-generator.com.

When running `hey` the following key metrics were observed:

1. Average response time is `~0.3` seconds, with the slowest being about twice that.

2. With the above `hey` configuration all requests are served in about 30 seconds with approximately 330-420 requests/sec.

Because of Python's global interpreter lock, Gunicorn has fairly limited concurrency. This
application would have probably limited benefits from vertical scaling, though improved
hardware would provide some improvement.

Given that the application is esssentially stateless it would benefit well from horizontal
scaling and the simple addition of HAProxy with a least connection config to a pool of 3-5
instances running this would see consistent performance improvements.

## SLA

First and foremost, we must establish the actual objectives for the service. As previously
established, current configuration can serve approximately 330 requests per-second on the low end.
As a safety measure, it's probably best to reduce that number by 10% and to rate-limit each
client.

Critical SLOs would be the following:

1. Uptime and availability. The application is stateless and redudancy can be added trivially.

2. Response time of the API. Times as slow as 0.75s have been observed, so it's probably
best to promise response times of ~1.5 seconds.

3. Integrity of the echoed data.

4. Requests per second.

5. Size of the requests. JSON is not memory efficient.

6. Points 4 and 5 become a measurement of throughput per client. This a very critical component
and it is not fungible. Echoing 4-5 requests of 200MB JSON documents is not the same as thousands
of small JSON documents.

Metrics and SLIs

1. First and foremost we need to monitor for 5XX errors as these are a major red flag for a
failing/degrading web service and even a single 5XX error can be an SLA breaking event.

2. CPU and memory are obviously critical components to monitor in any system. The application
is not disk I/O bound so this is not important.

3. Total number of connections to the service. This is especially important for a load balanced
service.

4. API canary. There needs to be a continous health check on the `/api/echo` path, validating both
response time and message integrity.

5. Auto-scaling. As this service grows, so to must its scalability. We need positive feedback
that new nodes hosting the service are coming online in a timely manner, and are healthy and
that service also scales down. If a service fails to autoscale it can be catastrophic.